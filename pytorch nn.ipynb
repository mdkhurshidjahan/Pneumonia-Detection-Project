{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2ec528f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as kr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import lime\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2b2c4a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 392 files belonging to 2 classes.\n",
      "Found 146 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "img_height = 180\n",
    "img_width = 180\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = kr.utils.image_dataset_from_directory(\n",
    "    r\"C:\\Users\\pirat\\Desktop\\cse498r\\PNEUMONIA classificatiopn\\train\",\n",
    "    seed = 753,\n",
    "    image_size = (img_height,img_width)\n",
    ")\n",
    "test_ds = kr.utils.image_dataset_from_directory(\n",
    "    r\"C:\\Users\\pirat\\Desktop\\cse498r\\PNEUMONIA classificatiopn\\test\",\n",
    "    seed = 753,\n",
    "    image_size = (img_height,img_width)\n",
    ")\n",
    "\n",
    "\n",
    "class_names = test_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b934de4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.784375 0.215625]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def count(counts, batch):\n",
    "  features, labels = batch\n",
    "  class_1 = (labels == 1)\n",
    "  class_1 = tf.cast(class_1, tf.int32)\n",
    "\n",
    "  class_0 = (labels == 0)\n",
    "  class_0 = tf.cast(class_0, tf.int32)\n",
    "\n",
    "  counts['class_0'] += tf.reduce_sum(class_0)\n",
    "  counts['class_1'] += tf.reduce_sum(class_1)\n",
    "\n",
    "  return counts\n",
    "\n",
    "counts = train_ds.take(10).reduce(\n",
    "    initial_state={'class_0': 0, 'class_1': 0},\n",
    "    reduce_func=count)\n",
    "\n",
    "counts = np.array([counts['class_0'].numpy(),\n",
    "                   counts['class_1'].numpy()]).astype(np.float32)\n",
    "\n",
    "fractions = counts / counts.sum()\n",
    "print(fractions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4fd5ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_func(features, label):\n",
    "  return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e50b0e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_ds = (\n",
    "    train_ds\n",
    "    .unbatch()\n",
    "    .rejection_resample(class_func, target_dist=[0.33,0.33],\n",
    "                        initial_dist=fractions)\n",
    "    .batch(32))\n",
    "\n",
    "balanced_train_ds = resample_ds.map(lambda extra_label, features_and_label: features_and_label)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = balanced_train_ds.cache().prefetch(buffer_size = AUTOTUNE)\n",
    "val_ds = test_ds.cache().prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8d546f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.VGG19(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    pooling=\"max\",\n",
    "    classes=1,  # Changed to 1 for binary classification\n",
    "    classifier_activation=\"sigmoid\"  # Changed to 'sigmoid' for binary classification\n",
    ")\n",
    "\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c75bf6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([127.5]*3)\n",
    "var = mean ** 2\n",
    "norm_layer = kr.layers.experimental.preprocessing.Normalization(mean=mean,variance=var)\n",
    "\n",
    "data_augmentation = kr.Sequential(\n",
    "  [\n",
    "    kr.layers.RandomFlip(\"horizontal\",input_shape=(img_height, img_width, 3)),\n",
    "    kr.layers.RandomRotation(0.3),\n",
    "    kr.layers.RandomZoom(-0.1),\n",
    "    kr.layers.RandomHeight(0.1),\n",
    "    kr.layers.RandomWidth(0.1)\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b0b74393",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = kr.Input(shape=(180,180,3))\n",
    "mean = np.array([127.5]*3)\n",
    "var = mean ** 2\n",
    "\n",
    "\n",
    "norm_layer = kr.layers.experimental.preprocessing.Normalization(mean=mean,variance=var)\n",
    "x = norm_layer(inputs)\n",
    "\n",
    "x = base_model(x)\n",
    "\n",
    "x = kr.layers.Dense(256)(x)\n",
    "x = kr.layers.Dense(64)(x)\n",
    "output = kr.layers.Dense(3, activation=\"softmax\")(x)\n",
    "model_fin = kr.Model(inputs,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "be8e89e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 180, 180, 3)]     0         \n",
      "                                                                 \n",
      " normalization_9 (Normaliza  (None, 180, 180, 3)       0         \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " vgg19 (Functional)          (None, 512)               20024384  \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20172355 (76.95 MB)\n",
      "Trainable params: 147971 (578.01 KB)\n",
      "Non-trainable params: 20024384 (76.39 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_fin.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "87f5d7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras as kr\n",
    "\n",
    "# Assuming you've defined your model 'model_fin' as mentioned in the previous snippet\n",
    "\n",
    "optimizer = kr.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model_fin.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),  # Binary cross-entropy for binary classification\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f7f05c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 2432, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py\", line 5809, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 3) vs (None, 1)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m model_fin\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      2\u001b[0m     train_ds,\n\u001b[0;32m      3\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mtest_ds,\n\u001b[0;32m      4\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m      5\u001b[0m     shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m      6\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filei0wi2mff.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 2432, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py\", line 5809, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 3) vs (None, 1)).\n"
     ]
    }
   ],
   "source": [
    "history = model_fin.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=10,\n",
    "    shuffle = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ba4d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0f4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab13317d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
