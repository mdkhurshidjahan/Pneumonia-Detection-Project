{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb5806fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "083a09d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder()\n",
    "encoder.fit([[0], [1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "854c4800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell updates result list for images with tumor\n",
    "\n",
    "data = []\n",
    "paths = []\n",
    "result = []\n",
    "\n",
    "for r, d, f in os.walk(r'C:\\Users\\pirat\\Downloads\\pneumonia 2-20240125T203918Z-001\\classification\\pneumonia'):\n",
    "    for file in f:\n",
    "        if '.jpg' in file:\n",
    "            paths.append(os.path.join(r, file))\n",
    "\n",
    "for path in paths:\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((128,128))\n",
    "    img = np.array(img)\n",
    "    if(img.shape == (128,128,3)):\n",
    "        data.append(np.array(img))\n",
    "        result.append(encoder.transform([[0]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34b82c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "for r, d, f in os.walk(r\"C:\\Users\\pirat\\Downloads\\pneumonia 2-20240125T203918Z-001\\classification\\normal\"):\n",
    "    for file in f:\n",
    "        if '.jpg' in file:\n",
    "            paths.append(os.path.join(r, file))\n",
    "\n",
    "for path in paths:\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((128,128))\n",
    "    img = np.array(img)\n",
    "    if(img.shape == (128,128,3)):\n",
    "        data.append(np.array(img))\n",
    "        result.append(encoder.transform([[1]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23a81528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(538, 128, 128, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7402e1a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1076 into shape (538,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(result)\n\u001b[1;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m538\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1076 into shape (538,1)"
     ]
    }
   ],
   "source": [
    "result = np.array(result)\n",
    "result = result.reshape(538,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d39482f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data, result, test_size=0.2, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a56da41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 128, 128, 32)      416       \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 128, 128, 32)      4128      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 128, 128, 32)      128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 64, 64, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 64, 64, 64)        8256      \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 64, 64, 64)        16448     \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 64, 64, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 32, 32, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 65536)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               33554944  \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33585089 (128.12 MB)\n",
      "Trainable params: 33584897 (128.12 MB)\n",
      "Non-trainable params: 192 (768.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), input_shape=(128, 128, 3), padding='same'))\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Changed to 1 neuron and 'sigmoid' activation for binary classification\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "655cb68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(430, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94334658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 2432, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py\", line 5809, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 1) vs (None, 2)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m40\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,validation_data \u001b[38;5;241m=\u001b[39m (x_test, y_test))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file2dg9uhqv.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 2432, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\pirat\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py\", line 5809, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 1) vs (None, 2)).\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 30, batch_size = 40, verbose = 1,validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d3af8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef2bb836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Prepare data and labels\n",
    "data = []\n",
    "result = []\n",
    "\n",
    "# Read pneumonia images\n",
    "for r, d, f in os.walk(r'C:\\Users\\pirat\\Downloads\\pneumonia 2-20240125T203918Z-001\\classification\\pneumonia'):\n",
    "    for file in f:\n",
    "        if '.jpg' in file:\n",
    "            img = Image.open(os.path.join(r, file))\n",
    "            img = img.resize((128, 128))\n",
    "            img = np.array(img)\n",
    "            if img.shape == (128, 128, 3):\n",
    "                data.append(np.array(img))\n",
    "                result.append(0)  # Label 0 for pneumonia\n",
    "\n",
    "# Read normal images\n",
    "for r, d, f in os.walk(r\"C:\\Users\\pirat\\Downloads\\pneumonia 2-20240125T203918Z-001\\classification\\normal\"):\n",
    "    for file in f:\n",
    "        if '.jpg' in file:\n",
    "            img = Image.open(os.path.join(r, file))\n",
    "            img = img.resize((128, 128))\n",
    "            img = np.array(img)\n",
    "            if img.shape == (128, 128, 3):\n",
    "                data.append(np.array(img))\n",
    "                result.append(1)  # Label 1 for normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42ad75fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "result = np.array(result)\n",
    "\n",
    "# Split data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, result, test_size=0.2, shuffle=True, random_state=0)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), input_shape=(128, 128, 3), padding='same'))\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0248aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='Adamax', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ecaf7d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "11/11 [==============================] - 13s 1s/step - loss: 14.1303 - accuracy: 0.6814 - val_loss: 25.6792 - val_accuracy: 0.8056\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 12s 1s/step - loss: 5.0445 - accuracy: 0.7233 - val_loss: 13.0667 - val_accuracy: 0.8056\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 12s 1s/step - loss: 2.3789 - accuracy: 0.7651 - val_loss: 5.5333 - val_accuracy: 0.8056\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 12s 1s/step - loss: 1.3785 - accuracy: 0.7512 - val_loss: 2.3809 - val_accuracy: 0.8056\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.6669 - accuracy: 0.8349 - val_loss: 0.7910 - val_accuracy: 0.7778\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.3894 - accuracy: 0.8302 - val_loss: 0.6963 - val_accuracy: 0.8056\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.3058 - accuracy: 0.8628 - val_loss: 0.4689 - val_accuracy: 0.7778\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.2813 - accuracy: 0.8860 - val_loss: 0.4217 - val_accuracy: 0.7778\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.2574 - accuracy: 0.8953 - val_loss: 0.4247 - val_accuracy: 0.7778\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.2572 - accuracy: 0.8884 - val_loss: 0.4289 - val_accuracy: 0.7778\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.2197 - accuracy: 0.9023 - val_loss: 0.4177 - val_accuracy: 0.7685\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.2299 - accuracy: 0.8814 - val_loss: 0.4206 - val_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 11s 1s/step - loss: 0.2367 - accuracy: 0.8953 - val_loss: 0.4201 - val_accuracy: 0.7963\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.2274 - accuracy: 0.9070 - val_loss: 0.4242 - val_accuracy: 0.7778\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.2155 - accuracy: 0.8977 - val_loss: 0.4590 - val_accuracy: 0.7407\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.2148 - accuracy: 0.8907 - val_loss: 0.4421 - val_accuracy: 0.7315\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.1888 - accuracy: 0.9116 - val_loss: 0.5090 - val_accuracy: 0.7037\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.1838 - accuracy: 0.9256 - val_loss: 0.4653 - val_accuracy: 0.7315\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.1698 - accuracy: 0.9326 - val_loss: 0.4755 - val_accuracy: 0.7315\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.1793 - accuracy: 0.9256 - val_loss: 0.5326 - val_accuracy: 0.6852\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.1444 - accuracy: 0.9442 - val_loss: 0.5407 - val_accuracy: 0.6852\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.1364 - accuracy: 0.9419 - val_loss: 0.5517 - val_accuracy: 0.7037\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.1559 - accuracy: 0.9326 - val_loss: 0.6054 - val_accuracy: 0.6667\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.1217 - accuracy: 0.9442 - val_loss: 0.5481 - val_accuracy: 0.7222\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.1031 - accuracy: 0.9605 - val_loss: 0.5854 - val_accuracy: 0.6852\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.1191 - accuracy: 0.9605 - val_loss: 0.5535 - val_accuracy: 0.7130\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.0929 - accuracy: 0.9698 - val_loss: 0.6276 - val_accuracy: 0.6944\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.1037 - accuracy: 0.9605 - val_loss: 0.6267 - val_accuracy: 0.6852\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.0835 - accuracy: 0.9767 - val_loss: 0.6270 - val_accuracy: 0.6944\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.0878 - accuracy: 0.9721 - val_loss: 0.7205 - val_accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=30, batch_size=40, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcf82e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(8)\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Prepare data and labels\n",
    "data = []\n",
    "result = []\n",
    "\n",
    "# Read pneumonia images\n",
    "for r, d, f in os.walk(r'C:\\Users\\pirat\\Downloads\\pneumonia 2-20240125T203918Z-001\\classification\\pneumonia'):\n",
    "    for file in f:\n",
    "        if '.jpg' in file:\n",
    "            img = Image.open(os.path.join(r, file))\n",
    "            img = img.resize((128, 128))\n",
    "            img = np.array(img)\n",
    "            if img.shape == (128, 128, 3):\n",
    "                data.append(np.array(img))\n",
    "                result.append(0)  # Label 0 for pneumonia\n",
    "\n",
    "# Read normal images\n",
    "for r, d, f in os.walk(r\"C:\\Users\\pirat\\Downloads\\pneumonia 2-20240125T203918Z-001\\classification\\normal\"):\n",
    "    for file in f:\n",
    "        if '.jpg' in file:\n",
    "            img = Image.open(os.path.join(r, file))\n",
    "            img = img.resize((128, 128))\n",
    "            img = np.array(img)\n",
    "            if img.shape == (128, 128, 3):\n",
    "                data.append(np.array(img))\n",
    "                result.append(1)  # Label 1 for normal\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "result = np.array(result)\n",
    "\n",
    "# Split data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, result, test_size=0.2, shuffle=True, random_state=0)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), input_shape=(128, 128, 3), padding='same'))\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Changed to 1 neuron and 'sigmoid' activation for binary classification\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=30, batch_size=40, verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "# Print model summary\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0846b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3bf732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "np.random.seed(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "668160f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data and labels\n",
    "data = []\n",
    "result = []\n",
    "\n",
    "# Read pneumonia images\n",
    "for r, d, f in os.walk(r'C:\\Users\\pirat\\Downloads\\pneumonia 2-20240125T203918Z-001\\classification\\pneumonia'):\n",
    "    for file in f:\n",
    "        if '.jpg' in file:\n",
    "            img = Image.open(os.path.join(r, file))\n",
    "            img = img.resize((128, 128))\n",
    "            img = np.array(img)\n",
    "            if img.shape == (128, 128, 3):\n",
    "                data.append(np.array(img))\n",
    "                result.append(0)  # Label 0 for pneumonia\n",
    "\n",
    "# Read normal images\n",
    "for r, d, f in os.walk(r\"C:\\Users\\pirat\\Downloads\\pneumonia 2-20240125T203918Z-001\\classification\\normal\"):\n",
    "    for file in f:\n",
    "        if '.jpg' in file:\n",
    "            img = Image.open(os.path.join(r, file))\n",
    "            img = img.resize((128, 128))\n",
    "            img = np.array(img)\n",
    "            if img.shape == (128, 128, 3):\n",
    "                data.append(np.array(img))\n",
    "                result.append(1)  # Label 1 for normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44326d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "result = np.array(result)\n",
    "\n",
    "# Initialize K-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=8)\n",
    "\n",
    "# Initialize lists to store evaluation results\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "# Iterate over folds\n",
    "for train_index, val_index in kfold.split(data):\n",
    "    x_train, x_val = data[train_index], data[val_index]\n",
    "    y_train, y_val = result[train_index], result[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "547aaa96",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1141349083.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[38], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    model = Sequential()\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), input_shape=(128, 128, 3), padding='same'))\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adamax', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91679582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "11/11 [==============================] - 13s 1s/step - loss: 7.7896 - accuracy: 0.7000 - val_loss: 0.5546 - val_accuracy: 0.7870\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.5609 - accuracy: 0.7512 - val_loss: 0.5340 - val_accuracy: 0.7870\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.5463 - accuracy: 0.7837 - val_loss: 0.5067 - val_accuracy: 0.7870\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.5093 - accuracy: 0.7814 - val_loss: 0.4765 - val_accuracy: 0.7870\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.4877 - accuracy: 0.7884 - val_loss: 0.4634 - val_accuracy: 0.7870\n",
      "Epoch 6/30\n",
      " 3/11 [=======>......................] - ETA: 8s - loss: 0.4358 - accuracy: 0.7917"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 77\u001b[0m\n\u001b[0;32m     74\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdamax\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(x_val, y_val))\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Evaluate the model on training data\u001b[39;00m\n\u001b[0;32m     80\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(x_train, y_train, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mconcrete_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function(\u001b[38;5;241m*\u001b[39margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(8)\n",
    "\n",
    "# Prepare data and labels\n",
    "data = []\n",
    "result = []\n",
    "\n",
    "# Read pneumonia images\n",
    "for r, d, f in os.walk(r'C:\\Users\\pirat\\Downloads\\pneumonia 2-20240125T203918Z-001\\classification\\pneumonia'):\n",
    "    for file in f:\n",
    "        if '.jpg' in file:\n",
    "            img = Image.open(os.path.join(r, file))\n",
    "            img = img.resize((128, 128))\n",
    "            img = np.array(img)\n",
    "            if img.shape == (128, 128, 3):\n",
    "                data.append(np.array(img))\n",
    "                result.append(0)  # Label 0 for pneumonia\n",
    "\n",
    "# Read normal images\n",
    "for r, d, f in os.walk(r\"C:\\Users\\pirat\\Downloads\\pneumonia 2-20240125T203918Z-001\\classification\\normal\"):\n",
    "    for file in f:\n",
    "        if '.jpg' in file:\n",
    "            img = Image.open(os.path.join(r, file))\n",
    "            img = img.resize((128, 128))\n",
    "            img = np.array(img)\n",
    "            if img.shape == (128, 128, 3):\n",
    "                data.append(np.array(img))\n",
    "                result.append(1)  # Label 1 for normal\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "result = np.array(result)\n",
    "\n",
    "# Initialize K-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=8)\n",
    "\n",
    "# Initialize lists to store evaluation results\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "# Iterate over folds\n",
    "for train_index, val_index in kfold.split(data):\n",
    "    x_train, x_val = data[train_index], data[val_index]\n",
    "    y_train, y_val = result[train_index], result[val_index]\n",
    "    model = Sequential([\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(512, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(x_train, y_train, epochs=30, batch_size=40, verbose=1, validation_data=(x_val, y_val))\n",
    "\n",
    "    # Evaluate the model on training data\n",
    "    train_loss, train_acc = model.evaluate(x_train, y_train, verbose=0)\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    # Evaluate the model on validation data\n",
    "    val_loss, val_acc = model.evaluate(x_val, y_val, verbose=0)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "# Calculate and print mean accuracy\n",
    "print(\"Mean training accuracy:\", np.mean(train_accs))\n",
    "print(\"Mean validation accuracy:\", np.mean(val_accs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe41ab38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a06639e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fee8bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb4231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c55b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc356007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205e8950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031f3284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
